{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDRlGyyJG0uV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import Any, List, Optional, Dict\n",
        "\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from langchain.llms.base import LLM\n",
        "from langchain_experimental.agents import create_csv_agent\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class BedrockLLMConfig(BaseModel):\n",
        "    client: Any = Field(..., description=\"The boto3 client for Bedrock\")\n",
        "    model: str = Field(..., description=\"The model name\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "\n",
        "class BedrockLLM(LLM):\n",
        "    config: BedrockLLMConfig\n",
        "\n",
        "    def __init__(self, client: Any, model: str):\n",
        "        config = BedrockLLMConfig(client=client, model=model)\n",
        "        super().__init__(config=config)\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        body = json.dumps({\n",
        "            \"prompt\": f\"<s>[INST] {prompt} [/INST]\",\n",
        "            \"max_tokens\": 4096,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.9,\n",
        "        })\n",
        "        try:\n",
        "            response = self.config.client.invoke_model(\n",
        "                body=body,\n",
        "                modelId=self.config.model,\n",
        "                contentType=\"application/json\",\n",
        "                accept=\"application/json\",\n",
        "            )\n",
        "            response_body = json.loads(response['body'].read())\n",
        "            return response_body.get('outputs', [{}])[0].get('text', '')\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Bedrock: {str(e)}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom_bedrock\"\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Dict[str, Any]:\n",
        "        return {\"model\": self.config.model}\n",
        "\n",
        "\n",
        "def save_uploaded_file(uploaded_file):\n",
        "    temp_directory = \"temp_files\"\n",
        "    os.makedirs(temp_directory, exist_ok=True)\n",
        "    file_path = os.path.join(temp_directory, uploaded_file.name)\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "    return file_path\n",
        "\n",
        "\n",
        "def format_output(output: str) -> str:\n",
        "    # Clean and format the output\n",
        "    lines = output.split('\\n')\n",
        "    final_answer = None\n",
        "    actions = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith(\"Final Answer:\"):\n",
        "            final_answer = line\n",
        "        elif line.startswith(\"Observation:\"):\n",
        "            observation = line.split(\"Observation:\", 1)[1].strip()\n",
        "            if observation.startswith(\"City\"):\n",
        "                observation = \"\\n\" + observation.replace(\"dtype: float64\", \"\")\n",
        "                actions.append(observation)\n",
        "\n",
        "    formatted_output = \"\\n\\n\".join(actions)\n",
        "    if final_answer:\n",
        "        formatted_output += \"\\n\\n\" + final_answer\n",
        "\n",
        "    return formatted_output if formatted_output else output\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Set AWS credentials (replace placeholders with your actual credentials)\n",
        "    aws_access_key = ''\n",
        "    aws_secret_key = ''\n",
        "    aws_region = 'us-east-1'\n",
        "\n",
        "    # Set AWS environment variables\n",
        "    os.environ['AWS_ACCESS_KEY_ID'] = aws_access_key\n",
        "    os.environ['AWS_SECRET_ACCESS_KEY'] = aws_secret_key\n",
        "    os.environ['AWS_DEFAULT_REGION'] = aws_region\n",
        "\n",
        "    # AWS model configuration\n",
        "    aws_model_name = 'mistral.mixtral-8x7b-instruct-v0:1'\n",
        "\n",
        "    st.set_page_config(page_title=\"CSV Consultant\")\n",
        "    st.header(\"Ask your CSV ðŸ“ˆ\")\n",
        "\n",
        "    csv_file = st.file_uploader(\"Upload a CSV file\", type=\"csv\")\n",
        "    if csv_file is not None:\n",
        "        file_path = save_uploaded_file(csv_file)\n",
        "\n",
        "        try:\n",
        "            # Initialize Bedrock client\n",
        "            bedrock_client = boto3.client(\n",
        "                service_name=\"bedrock-runtime\",\n",
        "                region_name=aws_region,\n",
        "            )\n",
        "\n",
        "            # Initialize the custom LLM\n",
        "            llm = BedrockLLM(client=bedrock_client, model=aws_model_name)\n",
        "\n",
        "            # Create LangChain agent for CSV interaction\n",
        "            agent = create_csv_agent(\n",
        "                llm=llm,\n",
        "                path=file_path,\n",
        "                verbose=True,\n",
        "                handle_parsing_errors=True,  # Enable handling of parsing errors\n",
        "                allow_python_repl=True,\n",
        "                allow_dangerous_code=True  # Be cautious with this setting\n",
        "            )\n",
        "\n",
        "            user_question = st.text_input(\"Ask a question about your CSV: \")\n",
        "\n",
        "            if user_question and user_question.strip():\n",
        "                with st.spinner(text=\"In progress...\"):\n",
        "                    try:\n",
        "                        response = agent.run(user_question)\n",
        "                        formatted_response = format_output(response)\n",
        "                        st.write(formatted_response)\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"An error occurred while running the agent: {str(e)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during setup: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}